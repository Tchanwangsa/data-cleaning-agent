{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691226d2",
   "metadata": {},
   "source": [
    "## **Feature:** [FEATURE_NAME]\n",
    "\n",
    "**Names:** [YOUR_NAME]\n",
    "\n",
    "### **What it does**\n",
    "[Brief description]\n",
    "\n",
    "### **Helper Functions**\n",
    "[List Helper Functions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPEN_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI  \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60424d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_function_1(df, param=None):\n",
    "    \"\"\"What this helper does\"\"\"\n",
    "    # Your code here\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46a090e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_function_2(series, method='default'):\n",
    "    \"\"\"What this helper does\"\"\"\n",
    "    # Your code here\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feature(df, user_query):\n",
    "    \"\"\"\n",
    "    Main function that gets called by the main router.\n",
    "    MUST take (user_query, df) and return df\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Create helper docs (Reimplement with real)\n",
    "    helper_docs = \"\"\"\n",
    "    - helper_function_1(): [description] \n",
    "    - helper_function_2(): [description]\n",
    "    \"\"\"\n",
    "    \n",
    "    # LLM Prompt\n",
    "    prompt = f\"\"\"\n",
    "    Dataset: {df.shape}\n",
    "    Columns: {list(df.columns)}\n",
    "    User wants: {user_query}\n",
    "    \n",
    "    Helper functions available:\n",
    "    {helper_docs}\n",
    "    \n",
    "    Generate pandas code using helpers where possible. Return only code.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call LLM\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\") # gpt-3.5 for development\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    generated_code = response.content.strip()\n",
    "    \n",
    "    # Execute code\n",
    "    try:\n",
    "        exec_env = {\n",
    "            'df': df.copy(),\n",
    "            'pd': pd,\n",
    "            'np': np,\n",
    "            'helper_function_1': helper_function_1, # TODO: REPLACE WITH FUNCTION\n",
    "            'helper_function_2': helper_function_2, # TODO: REPLACE WITH FUNCTION\n",
    "            'result_df': df.copy()\n",
    "        }\n",
    "        exec(generated_code,exec_env)\n",
    "        return exec_env['result_df']\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST OUT YOUR FEATURE\n",
    "\n",
    "## Import Data\n",
    "\n",
    "## Run code\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
